{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9cc5cb-3ce4-4e59-abd5-75785e4eb067",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import joblib\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas import option_context\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.inter_rater import aggregate_raters\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.stats import mannwhitneyu,shapiro,ttest_ind\n",
    "\n",
    "import cliffsDelta as cd\n",
    "import GenerateActivities as gat\n",
    "import important_features as imf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a11378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas==2.2.3\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting numpy==2.1.2\n",
      "  Using cached numpy-2.1.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting python-dateutil==2.9.0.post0\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting scikit-learn==1.5.2\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "Collecting scipy==1.14.1\n",
      "  Using cached scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "Requirement already satisfied: tqdm==4.66.5 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 7)) (4.66.5)\n",
      "Requirement already satisfied: urllib3==2.2.3 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 8)) (2.2.3)\n",
      "Collecting joblib==1.4.2\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting jupyterlab==4.2.5\n",
      "  Using cached jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n",
      "Collecting matplotlib==3.9.2\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "Collecting seaborn==0.13.2\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting json5==0.9.25\n",
      "  Using cached json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Collecting statsmodels==0.14.4\n",
      "  Using cached statsmodels-0.14.4-cp310-cp310-win_amd64.whl (9.8 MB)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241003 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 16)) (2.9.0.20241003)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2021.3)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil==2.9.0.post0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from tqdm==4.66.5->-r requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (6.4.2)\n",
      "Requirement already satisfied: traitlets in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (5.14.3)\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (4.9.2)\n",
      "Collecting httpx>=0.25.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (3.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (21.3)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.0.1)\n",
      "Collecting notebook-shim>=0.2\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Collecting jupyter-lsp>=2.0.0\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\program files\\python310\\lib\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (58.1.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyterlab==4.2.5->-r requirements.txt (line 10)) (6.9.1)\n",
      "Collecting async-lru>=1.0.0\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib==3.9.2->-r requirements.txt (line 11)) (1.3.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: bleach 4.1.0 does not provide the extra 'css'\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib==3.9.2->-r requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib==3.9.2->-r requirements.txt (line 11)) (4.29.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib==3.9.2->-r requirements.txt (line 11)) (3.0.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib==3.9.2->-r requirements.txt (line 11)) (9.0.1)\n",
      "Collecting patsy>=0.5.6\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from async-lru>=1.0.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (4.12.2)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (7.1.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.5.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (8.0.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jinja2>=3.0.3->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.13.1)\n",
      "Collecting jupyter-events>=0.11.0\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Collecting nbconvert>=6.4.4\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (26.2.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (21.3.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.0.2)\n",
      "Collecting overrides>=5.0\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.8.0)\n",
      "Collecting jupyter-client<8.0\n",
      "  Using cached jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
      "Collecting nbformat>=5.3.0\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.13.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.8.3)\n",
      "Collecting jupyter-core\n",
      "  Using cached jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.5.1)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core->jupyterlab==4.2.5->-r requirements.txt (line 10)) (303)\n",
      "Collecting babel>=2.10\n",
      "  Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Collecting jsonschema>=4.18.0\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx>=0.25.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.3.1)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (21.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (3.0.28)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.18.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.11.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: black in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (22.1.0)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.23.1)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-client<8.0->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.4)\n",
      "Collecting python-json-logger>=2.0.4\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting pyyaml>=5.3\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.1.4)\n",
      "Collecting pywinpty>=2.0.1\n",
      "  Using cached pywinpty-2.0.15-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.5.11)\n",
      "Collecting mistune<4,>=2.0.3\n",
      "  Using cached mistune-3.1.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.7.1)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.21.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.8.3)\n",
      "Requirement already satisfied: uri-template in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.3.0)\n",
      "Collecting isoduration\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab==4.2.5->-r requirements.txt (line 10)) (24.11.1)\n",
      "Collecting fqdn\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from black->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (8.0.4)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from black->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from black->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.4.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ingri\\appdata\\roaming\\python\\python310\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.2.5->-r requirements.txt (line 10)) (2.21)\n",
      "Collecting arrow>=0.15.0\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Installing collected packages: pyyaml, pywinpty, python-json-logger, python-dateutil, packaging, overrides, numpy, mistune, jupyter-core, jsonpointer, json5, joblib, idna, h11, fqdn, exceptiongroup, charset-normalizer, certifi, beautifulsoup4, babel, attrs, async-lru, scipy, requests, referencing, patsy, pandas, jupyter-client, httpcore, contourpy, arrow, anyio, statsmodels, scikit-learn, matplotlib, jupyter-server-terminals, jsonschema-specifications, isoduration, httpx, seaborn, jsonschema, nbformat, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab\n",
      "  Attempting uninstall: pywinpty\n",
      "    Found existing installation: pywinpty 2.0.2\n",
      "    Uninstalling pywinpty-2.0.2:\n",
      "      Successfully uninstalled pywinpty-2.0.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.2\n",
      "    Uninstalling numpy-1.22.2:\n",
      "      Successfully uninstalled numpy-1.22.2\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.9.2\n",
      "    Uninstalling jupyter-core-4.9.2:\n",
      "      Successfully uninstalled jupyter-core-4.9.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.8.0\n",
      "    Uninstalling scipy-1.8.0:\n",
      "      Successfully uninstalled scipy-1.8.0\n",
      "  Attempting uninstall: patsy\n",
      "    Found existing installation: patsy 0.5.2\n",
      "    Uninstalling patsy-0.5.2:\n",
      "      Successfully uninstalled patsy-0.5.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.1\n",
      "    Uninstalling pandas-1.4.1:\n",
      "      Successfully uninstalled pandas-1.4.1\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 7.1.2\n",
      "    Uninstalling jupyter-client-7.1.2:\n",
      "      Successfully uninstalled jupyter-client-7.1.2\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.13.2\n",
      "    Uninstalling statsmodels-0.13.2:\n",
      "      Successfully uninstalled statsmodels-0.13.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.1\n",
      "    Uninstalling matplotlib-3.5.1:\n",
      "      Successfully uninstalled matplotlib-3.5.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.11.2\n",
      "    Uninstalling seaborn-0.11.2:\n",
      "      Successfully uninstalled seaborn-0.11.2\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.4.0\n",
      "    Uninstalling jsonschema-4.4.0:\n",
      "      Successfully uninstalled jsonschema-4.4.0\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.1.3\n",
      "    Uninstalling nbformat-5.1.3:\n",
      "      Successfully uninstalled nbformat-5.1.3\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.4.2\n",
      "    Uninstalling nbconvert-6.4.2:\n",
      "      Successfully uninstalled nbconvert-6.4.2\n",
      "Successfully installed anyio-4.8.0 arrow-1.3.0 async-lru-2.0.4 attrs-25.1.0 babel-2.17.0 beautifulsoup4-4.13.3 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.1 exceptiongroup-1.2.2 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 isoduration-20.11.0 joblib-1.4.2 json5-0.9.25 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-client-7.4.9 jupyter-core-5.7.2 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-server-2.27.3 matplotlib-3.9.2 mistune-3.1.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-shim-0.2.4 numpy-2.1.2 overrides-7.7.0 packaging-24.2 pandas-2.2.3 patsy-1.0.1 python-dateutil-2.9.0.post0 python-json-logger-3.3.0 pywinpty-2.0.15 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.3 scikit-learn-1.5.2 scipy-1.14.1 seaborn-0.13.2 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f34e37-48e6-4033-b30f-5ba256427f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_ROOT = \"https://api.github.com\"\n",
    "TOKEN = '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' # write your GitHub API key here\n",
    "HEADERS={'Authorization':'token '+TOKEN}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c72b-abe2-46b8-9034-1d9c7d98d3ad",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6e0c3-b012-4f00-a033-ddf3b74747c7",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cc77d-eedd-4b5a-a560-b17a5a2b4cc4",
   "metadata": {},
   "source": [
    "#### Write an automated Python script to identify all GitHub bot actors in the list of contributors, by querying the GitHub REST API users endpoint and extracting the required information to make this decision. \n",
    "\n",
    "#### More information: You can search for the \"type\" key in the obtianed JSON result, If it is \"Bot\", then it is a bot actor, if it is \"User\", then it is an account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0275f0-5c13-42ea-9025-5ea307d6398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      contributor bothunter_type\n",
      "0                    Anurag-Varma          Human\n",
      "1                 DilumAluthgeBot          Human\n",
      "2                    ElektrikAkar          Human\n",
      "3                JuliaRegistrator            Bot\n",
      "4                   ManonMarchand          Human\n",
      "5                  RussellGarwood          Human\n",
      "6                   VincentAuriau          Human\n",
      "7                     aloctavodia          Human\n",
      "8                        avehtari          Human\n",
      "9                  bioc-issue-bot            Bot\n",
      "10                         bozaah          Human\n",
      "11                     chainer-ci            Bot\n",
      "12                        cpondoc          Human\n",
      "13                     doronbehar          Human\n",
      "14                      fingolfin          Human\n",
      "15            github-actions[bot]            Bot\n",
      "16  github-advanced-security[bot]            Bot\n",
      "17                hackmd-hub[bot]            Bot\n",
      "18                       harperjf          Human\n",
      "19                      jClugstor          Human\n",
      "20                        jmineau          Human\n",
      "21                        kanav99          Human\n",
      "22                       ldouteau          Human\n",
      "23             lumberbot-app[bot]            Bot\n",
      "24                      martenson          Human\n",
      "25                   mergify[bot]            Bot\n",
      "26                       mikelkou          Human\n",
      "27                     natalie-wa          Human\n",
      "28                  oscarbenjamin          Human\n",
      "29                     plover0226          Human\n",
      "30                         rtimms          Human\n",
      "31                    scverse-bot            Bot\n",
      "32                         slager          Human\n",
      "33                     spyder-bot            Bot\n",
      "34                      sympy-bot            Bot\n",
      "35                        timholy          Human\n",
      "36     transifex-integration[bot]            Bot\n",
      "37                        weblate            Bot\n",
      "38                   welcome[bot]            Bot\n",
      "39                        wlandau          Human\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the given <sample>.csv file into a pandas DataFrame (df).\n",
    "# 2. Make sure there are 2 columns, one column name is \"contributor\" that has the name of the contributor, \n",
    "#    and another column name is \"bothunter_type\" that you will use later on in this assignment.\n",
    "# 3. Display the DataFrame.\n",
    "\n",
    "# YOUR CODE BELOW\n",
    "\n",
    "# Replace with the actual CSV file path\n",
    "csv_file = \"E:\\software evolution\\Software_Evolution_TP_bots\\Contributors\\sample7.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Ensure the required columns exist, otherwise create them\n",
    "required_columns = [\"contributor\", \"bothunter_type\"]\n",
    "\n",
    "# If \"contributor\" column is missing, raise an error\n",
    "if \"contributor\" not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain a 'contributor' column.\")\n",
    "\n",
    "# If \"bothunter_type\" is missing, add it with default empty values\n",
    "if \"bothunter_type\" not in df.columns:\n",
    "    df[\"bothunter_type\"] = \"\"\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9312364-57d3-4f26-a216-82a22eea8349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of contributors: ['Anurag-Varma', 'DilumAluthgeBot', 'ElektrikAkar', 'JuliaRegistrator', 'ManonMarchand', 'RussellGarwood', 'VincentAuriau', 'aloctavodia', 'avehtari', 'bioc-issue-bot', 'bozaah', 'chainer-ci', 'cpondoc', 'doronbehar', 'fingolfin', 'github-actions[bot]', 'github-advanced-security[bot]', 'hackmd-hub[bot]', 'harperjf', 'jClugstor', 'jmineau', 'kanav99', 'ldouteau', 'lumberbot-app[bot]', 'martenson', 'mergify[bot]', 'mikelkou', 'natalie-wa', 'oscarbenjamin', 'plover0226', 'rtimms', 'scverse-bot', 'slager', 'spyder-bot', 'sympy-bot', 'timholy', 'transifex-integration[bot]', 'weblate', 'welcome[bot]', 'wlandau']\n"
     ]
    }
   ],
   "source": [
    "# 1. Store the names of the contributors in a list\n",
    "# 2. print the list\n",
    "\n",
    "# YOUR CODE BELOW\n",
    "\n",
    "# Store the contributor names in a list\n",
    "contributors_list = df[\"contributor\"].tolist()\n",
    "\n",
    "# Print the list of contributors\n",
    "print(\"List of contributors:\", contributors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd6ab44-f113-466a-863c-862674798f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      contributor    app\n",
      "0                    Anurag-Varma  False\n",
      "1                 DilumAluthgeBot  False\n",
      "2                    ElektrikAkar  False\n",
      "3                JuliaRegistrator  False\n",
      "4                   ManonMarchand  False\n",
      "5                  RussellGarwood  False\n",
      "6                   VincentAuriau  False\n",
      "7                     aloctavodia  False\n",
      "8                        avehtari  False\n",
      "9                  bioc-issue-bot  False\n",
      "10                         bozaah  False\n",
      "11                     chainer-ci  False\n",
      "12                        cpondoc  False\n",
      "13                     doronbehar  False\n",
      "14                      fingolfin  False\n",
      "15            github-actions[bot]   True\n",
      "16  github-advanced-security[bot]   True\n",
      "17                hackmd-hub[bot]   True\n",
      "18                       harperjf  False\n",
      "19                      jClugstor  False\n",
      "20                        jmineau  False\n",
      "21                        kanav99  False\n",
      "22                       ldouteau  False\n",
      "23             lumberbot-app[bot]   True\n",
      "24                      martenson  False\n",
      "25                   mergify[bot]   True\n",
      "26                       mikelkou  False\n",
      "27                     natalie-wa  False\n",
      "28                  oscarbenjamin  False\n",
      "29                     plover0226  False\n",
      "30                         rtimms  False\n",
      "31                    scverse-bot  False\n",
      "32                         slager  False\n",
      "33                     spyder-bot  False\n",
      "34                      sympy-bot  False\n",
      "35                        timholy  False\n",
      "36     transifex-integration[bot]   True\n",
      "37                        weblate  False\n",
      "38                   welcome[bot]   True\n",
      "39                        wlandau  False\n"
     ]
    }
   ],
   "source": [
    "# 1. Using a for loop, iterate over each contributor in the list and query the GitHub Users API.\n",
    "#    You can use \"query = f'{QUERY_ROOT}/users/{contributor}'\", where QUERY_ROOT is defined at the beginning of this notebook \n",
    "#    and 'contributor' is each individual contributor from the list\n",
    "# 2. Get the response using 'response = requests.get(query, headers=HEADERS)'.\n",
    "# 3. convert the response to JSON using 'json_response = response.json()'.\n",
    "# 4. Iterate over each JSON response and get the value of the 'type' key. If it is \"Bot\" then the contributor is a bot actor, \n",
    "#    if \"User\" then the contributor is an account. You should boolean values to indicate if the contributor is a bot actor (True) or User/Organisation (False)\n",
    "# 5. Save these results in list of dictionary of the form [{'contributor': <contributor name>, 'app': <boolean value>}, {...}, {...}, {...}].\n",
    "#    Lets call this list as \"app_dict\"\n",
    "# 6. Finally convert this list of dictionary to DataFrame by writing 'pd.DataFrame.from_dict(app_dict)'\n",
    "# 7. Display the DataFrame. This should have two columns - contributor and app\n",
    "\n",
    "# YOUR CODE BELOW\n",
    "app_dict = []\n",
    "\n",
    "for contributor in contributors_list:\n",
    "    query = f'{QUERY_ROOT}/users/{contributor}'\n",
    "    response = requests.get(query,headers=HEADERS)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        is_bot = json_response.get(\"type\") == \"Bot\"\n",
    "        app_dict.append({\"contributor\": contributor, \"app\": is_bot})\n",
    "    else:\n",
    "        print(f\"Error fetching data for {contributor}: {response.status_code}\")\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "app_df = pd.DataFrame.from_dict(app_dict)\n",
    "\n",
    "print(app_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a784f-8b41-488b-8034-7f66ed9b6d97",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "#### Add a new 'actor' column in the CSV file to store this information. You can write True if it is a bot actor and False if it is not.\n",
    "\n",
    "#### Report on the total number of GitHub bot actors, and User accounts present in the list of accounts of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "242398c5-d3ae-472f-99e8-ac86be7897c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total des Bot Actors sur GitHub : 7\n",
      "Total des Comptes Utilisateurs : 33\n",
      "\n",
      " Aperçu du fichier mis à jour :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>bothunter_type</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>github-advanced-security[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hackmd-hub[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lumberbot-app[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mergify[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transifex-integration[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>welcome[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      contributor bothunter_type   app\n",
       "15            github-actions[bot]            Bot  True\n",
       "16  github-advanced-security[bot]            Bot  True\n",
       "17                hackmd-hub[bot]            Bot  True\n",
       "23             lumberbot-app[bot]            Bot  True\n",
       "25                   mergify[bot]            Bot  True\n",
       "36     transifex-integration[bot]            Bot  True\n",
       "38                   welcome[bot]            Bot  True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the app DataFrame to df by writing 'pd.merge(df, <app df>, on='contributor'). This is similar to SQL join on primary key 'contributor'.\n",
    "# The resultant df should have 3 columns - contributor, bothunter_type and user_type.\n",
    "\n",
    "# YOUR CODE BELOW\n",
    " \n",
    "merged_df =pd.merge(df, app_df, on='contributor')\n",
    "\n",
    "# Count the number of bot actors and user accounts\n",
    "num_bots = merged_df[\"app\"].sum()  # Count where actor is True\n",
    "num_users = len(merged_df) - num_bots  # Remaining are users\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "updated_csv_file = \"updated_sample.csv\"\n",
    "merged_df.to_csv(updated_csv_file, index=False)\n",
    "\n",
    "# Print the report\n",
    "print(f\"Total des Bot Actors sur GitHub : {num_bots}\")\n",
    "print(f\"Total des Comptes Utilisateurs : {num_users}\\n\")\n",
    "\n",
    "# Afficher les 10 premières lignes du DataFrame final\n",
    "print(\" Aperçu du fichier mis à jour :\")\n",
    "merged_df[merged_df[\"app\"]==True] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ba7d8-7a6f-4485-8e7b-bc5a00646021",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "#### For each bot actor, write their purpose, the task that they automate by looking at their GitHub profile, homepage, information on the GitHub Marketplace, or other documentation that you can find online.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c720ee1",
   "metadata": {},
   "source": [
    "## github-actions[bot]: \n",
    " is a CI/CD (Continuous Integration/Continuous Deployment) platform that allows developers to automate their build, test, and deployment pipelines. It enables the creation of workflows that can be triggered by various events in a repository, such as pull requests, issues, or commits\n",
    "## github-advanced-security[bot]:\n",
    "offers enhanced security features to help improve and maintain the quality of your code. These features are available for enterprise accounts on GitHub Enterprise Cloud and GitHub Enterprise Server, and some are also available for public repositories on GitHub\n",
    "## hackmd-hub[bot]:\n",
    " is a real-time collaborative Markdown editor that syncs with GitHub.\n",
    "Join Kuberenetes, Ruby-lang, Matplotlib, Microsoft and many others in collaborating on markdown docs!\n",
    "With this app, you can:\n",
    " Collaborate on Markdown files\n",
    " Sync HackMD Markdown files with GitHub repository\n",
    " Let the community know where live collaboration is happening\n",
    "## lumberbot-app[bot]\n",
    "## mergify[bot]: \n",
    "Mergify is a solution making your code merge faster, safer, and cheaper by virtue of:\n",
    "The Merge Queue - Queue, Update and Merge your Pull Requests.\n",
    "The Workflow Automation - Automate your code merge processes.\n",
    "## transifex-integration[bot]: \n",
    "Seamlessly connect and integrate your GitHub repositories to your Transifex projects. Once integrated: Fully translated content from your Transifex project will be automatically pushed back to your GitHub repository (via commit or Pull Request, depending on which you select).\n",
    "## welcome[bot]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e178f-2b41-4758-b075-e2eea47f3991",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bb032-1b55-402e-8074-42f2210f3a16",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48285de2-8b3a-481a-bf93-b99295ba8a4a",
   "metadata": {},
   "source": [
    "#### Write an automated script to use BIMBAS (Bot Identification Model Based on Activity Sequences) to obtain a prediction of the GitHub contributor type (Bot or Human) for the contributors present in your dataset.\n",
    "\n",
    "#### Folow the steps given in each cell to use BIMBAS and obtain predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb9ed4-b5b9-4be5-aaac-02948a7188cc",
   "metadata": {},
   "source": [
    "### Read all the events and select the events performed by the contributors present in the given set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab8cc3-b9ca-4b88-bddb-dafe9f3cc09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>login</th>\n",
       "      <th>repository</th>\n",
       "      <th>created_at</th>\n",
       "      <th>action</th>\n",
       "      <th>PR_number</th>\n",
       "      <th>state</th>\n",
       "      <th>PR_node_id</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_node_id</th>\n",
       "      <th>merged</th>\n",
       "      <th>ref</th>\n",
       "      <th>ref_type</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>issue_node_id</th>\n",
       "      <th>issue_closed_at</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>release_node_id</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>39747396929</td>\n",
       "      <td>CommitCommentEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>QuantEcon/lecture-python-intro</td>\n",
       "      <td>2024-07-01 00:01:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CC_kwDOIy5DFs4IkKwX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QuantEcon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>39747413489</td>\n",
       "      <td>CommitCommentEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>QuantEcon/lecture-python-intro</td>\n",
       "      <td>2024-07-01 00:03:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CC_kwDOIy5DFs4IkKw0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QuantEcon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>39747416135</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>napari/npe2api</td>\n",
       "      <td>2024-07-01 00:03:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>napari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>39747427332</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>SciML/PubChem.jl</td>\n",
       "      <td>2024-07-01 00:04:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compathelper/new_version/2024-07-01-00-04-42-9...</td>\n",
       "      <td>branch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SciML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>39747452343</td>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>pandas-dev/pandas</td>\n",
       "      <td>2024-07-01 00:07:06</td>\n",
       "      <td>created</td>\n",
       "      <td>58814.0</td>\n",
       "      <td>open</td>\n",
       "      <td>PR_kwDOAA0YD85wSOEO</td>\n",
       "      <td>...</td>\n",
       "      <td>IC_kwDOAA0YD86DD0Tu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pandas-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358385</th>\n",
       "      <td>358385</td>\n",
       "      <td>42415261485</td>\n",
       "      <td>CommitCommentEvent</td>\n",
       "      <td>JuliaRegistrator</td>\n",
       "      <td>SciML/LineSearch.jl</td>\n",
       "      <td>2024-09-30 23:21:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CC_kwDOLCAB0M4IyT9_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SciML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358391</th>\n",
       "      <td>358391</td>\n",
       "      <td>42415303969</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>SciML/LineSearch.jl</td>\n",
       "      <td>2024-09-30 23:24:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SciML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358401</th>\n",
       "      <td>358401</td>\n",
       "      <td>42415474205</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>Bioconductor/gha-build-jupyter-release-amd64</td>\n",
       "      <td>2024-09-30 23:34:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bioconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358403</th>\n",
       "      <td>358403</td>\n",
       "      <td>42415512378</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>napari/npe2api</td>\n",
       "      <td>2024-09-30 23:37:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>napari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358420</th>\n",
       "      <td>358420</td>\n",
       "      <td>42415587765</td>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>welcome[bot]</td>\n",
       "      <td>pydata/xarray</td>\n",
       "      <td>2024-09-30 23:41:50</td>\n",
       "      <td>created</td>\n",
       "      <td>9561.0</td>\n",
       "      <td>open</td>\n",
       "      <td>PR_kwDOAMm_X859Ls6n</td>\n",
       "      <td>...</td>\n",
       "      <td>IC_kwDOAMm_X86OIA0y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pydata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95129 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     event_id          event_type                login  \\\n",
       "6                6  39747396929  CommitCommentEvent  github-actions[bot]   \n",
       "15              15  39747413489  CommitCommentEvent  github-actions[bot]   \n",
       "16              16  39747416135           PushEvent  github-actions[bot]   \n",
       "21              21  39747427332         CreateEvent  github-actions[bot]   \n",
       "30              30  39747452343   IssueCommentEvent  github-actions[bot]   \n",
       "...            ...          ...                 ...                  ...   \n",
       "358385      358385  42415261485  CommitCommentEvent     JuliaRegistrator   \n",
       "358391      358391  42415303969           PushEvent  github-actions[bot]   \n",
       "358401      358401  42415474205           PushEvent  github-actions[bot]   \n",
       "358403      358403  42415512378           PushEvent  github-actions[bot]   \n",
       "358420      358420  42415587765   IssueCommentEvent         welcome[bot]   \n",
       "\n",
       "                                          repository          created_at  \\\n",
       "6                     QuantEcon/lecture-python-intro 2024-07-01 00:01:47   \n",
       "15                    QuantEcon/lecture-python-intro 2024-07-01 00:03:24   \n",
       "16                                    napari/npe2api 2024-07-01 00:03:40   \n",
       "21                                  SciML/PubChem.jl 2024-07-01 00:04:44   \n",
       "30                                 pandas-dev/pandas 2024-07-01 00:07:06   \n",
       "...                                              ...                 ...   \n",
       "358385                           SciML/LineSearch.jl 2024-09-30 23:21:33   \n",
       "358391                           SciML/LineSearch.jl 2024-09-30 23:24:21   \n",
       "358401  Bioconductor/gha-build-jupyter-release-amd64 2024-09-30 23:34:53   \n",
       "358403                                napari/npe2api 2024-09-30 23:37:12   \n",
       "358420                                 pydata/xarray 2024-09-30 23:41:50   \n",
       "\n",
       "         action  PR_number state           PR_node_id  ...  \\\n",
       "6           NaN        NaN   NaN                  NaN  ...   \n",
       "15          NaN        NaN   NaN                  NaN  ...   \n",
       "16          NaN        NaN   NaN                  NaN  ...   \n",
       "21          NaN        NaN   NaN                  NaN  ...   \n",
       "30      created    58814.0  open  PR_kwDOAA0YD85wSOEO  ...   \n",
       "...         ...        ...   ...                  ...  ...   \n",
       "358385      NaN        NaN   NaN                  NaN  ...   \n",
       "358391      NaN        NaN   NaN                  NaN  ...   \n",
       "358401      NaN        NaN   NaN                  NaN  ...   \n",
       "358403      NaN        NaN   NaN                  NaN  ...   \n",
       "358420  created     9561.0  open  PR_kwDOAMm_X859Ls6n  ...   \n",
       "\n",
       "            comment_node_id merged  \\\n",
       "6       CC_kwDOIy5DFs4IkKwX    NaN   \n",
       "15      CC_kwDOIy5DFs4IkKw0    NaN   \n",
       "16                      NaN    NaN   \n",
       "21                      NaN    NaN   \n",
       "30      IC_kwDOAA0YD86DD0Tu    NaN   \n",
       "...                     ...    ...   \n",
       "358385  CC_kwDOLCAB0M4IyT9_    NaN   \n",
       "358391                  NaN    NaN   \n",
       "358401                  NaN    NaN   \n",
       "358403                  NaN    NaN   \n",
       "358420  IC_kwDOAMm_X86OIA0y    NaN   \n",
       "\n",
       "                                                      ref ref_type  \\\n",
       "6                                                     NaN      NaN   \n",
       "15                                                    NaN      NaN   \n",
       "16                                                    NaN      NaN   \n",
       "21      compathelper/new_version/2024-07-01-00-04-42-9...   branch   \n",
       "30                                                    NaN      NaN   \n",
       "...                                                   ...      ...   \n",
       "358385                                                NaN      NaN   \n",
       "358391                                                NaN      NaN   \n",
       "358401                                                NaN      NaN   \n",
       "358403                                                NaN      NaN   \n",
       "358420                                                NaN      NaN   \n",
       "\n",
       "        issue_number issue_node_id issue_closed_at tag_name release_node_id  \\\n",
       "6                NaN           NaN             NaN      NaN             NaN   \n",
       "15               NaN           NaN             NaN      NaN             NaN   \n",
       "16               NaN           NaN             NaN      NaN             NaN   \n",
       "21               NaN           NaN             NaN      NaN             NaN   \n",
       "30               NaN           NaN             NaN      NaN             NaN   \n",
       "...              ...           ...             ...      ...             ...   \n",
       "358385           NaN           NaN             NaN      NaN             NaN   \n",
       "358391           NaN           NaN             NaN      NaN             NaN   \n",
       "358401           NaN           NaN             NaN      NaN             NaN   \n",
       "358403           NaN           NaN             NaN      NaN             NaN   \n",
       "358420           NaN           NaN             NaN      NaN             NaN   \n",
       "\n",
       "                 org  \n",
       "6          QuantEcon  \n",
       "15         QuantEcon  \n",
       "16            napari  \n",
       "21             SciML  \n",
       "30        pandas-dev  \n",
       "...              ...  \n",
       "358385         SciML  \n",
       "358391         SciML  \n",
       "358401  Bioconductor  \n",
       "358403        napari  \n",
       "358420        pydata  \n",
       "\n",
       "[95129 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Read the csv file of events (all_events.csv) provided along with this notebook\n",
    "# 2. Convert created_at column to datetime format \n",
    "#    One possible way is to use lambda function: \"events.assign(created_at=lambda d: pd.to_datetime(d.created_at, unit='ms'))\"\n",
    "# 3. Get the contributors provided to you in a list or use the contributors list that you created in Section 3 Question 1. \n",
    "#    e.g., ['contributor1', 'contributor2', 'contributor3',...]\n",
    "# 4. Select the events performed by these contributors alone. Do not consider all the events. You should consider only the events\n",
    "#    performed by the contributors provided to you. Hint: you can use the df.query function\n",
    "# 5. Display the considered events.\n",
    "\n",
    "# YOUR CODE BELOW\n",
    "\n",
    "#  Load the events CSV file\n",
    "events_file = \"all_events.csv\"  \n",
    "events = pd.read_csv(events_file)\n",
    "\n",
    "#  Convert 'created_at' column to datetime format\n",
    "events = events.assign(created_at=lambda d: pd.to_datetime(d.created_at, unit='ms'))\n",
    "  \n",
    "\n",
    "#  Filter events to include only those performed by contributors in the list\n",
    "filtered_events = events.query(\"login in @contributors_list\")\n",
    "\n",
    "#  Display the considered events\n",
    "filtered_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f221c-e9a6-463b-b76a-10c83f691fbd",
   "metadata": {},
   "source": [
    "### Execute BIMBAS to obtain the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f873efc-01b5-495e-8b99-87ce15962ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "# Use the following function the code below to obtain your predictions\n",
    "\n",
    "def execute_bimbas(contributors_list, selected_events):\n",
    "    '''\n",
    "    args: contributors_list (list) - list of contributors in the dataset provided to you\n",
    "          selected_events (DataFrame) - DataFrame of events performed by the considered contributors\n",
    "    return: bimbas_prediction (DataFrame) - DataFrame of preditions along with the confidence in prediction for each contributor\n",
    "    '''\n",
    "    result=pd.DataFrame()\n",
    "    temp_list = []\n",
    "    bimbas = joblib.load('bimbas.joblib')\n",
    "    date_limit = pd.to_datetime(selected_events.created_at.max()) + pd.DateOffset(-90)\n",
    "    \n",
    "    for contributor in tqdm(contributors_list):\n",
    "        # c = contributors[contributor]\n",
    "        activities = gat.activity_identification(selected_events.query('login==@contributor and created_at>=@date_limit'))\n",
    "        activity_features = (\n",
    "                            imf.extract_features(activities)\n",
    "                            .set_index([[contributor]])\n",
    "                            )\n",
    "        # features = pd.concat([features,activity_features])\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            probability = bimbas.predict_proba(activity_features)[0][1]\n",
    "        if(probability <= 0.5):\n",
    "            contributor_type = 'Human'\n",
    "        else:\n",
    "            contributor_type = 'Bot'\n",
    "        confidence = (abs(probability - 0.5)*2).round(3)\n",
    "    \n",
    "        pred = activity_features.set_index([[contributor]]).assign(\n",
    "            prediction=contributor_type,\n",
    "            confidence = confidence,\n",
    "            )\n",
    "        temp_list.extend([{'contributor':contributor,'bimbas_type':contributor_type,'confidence':confidence}])\n",
    "    \n",
    "    bimbas_prediction = pd.DataFrame.from_dict(temp_list)\n",
    "\n",
    "    return(bimbas_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abe1a50e-04a7-48b8-816d-5bf7f5df7738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>bimbas_type</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anurag-Varma</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DilumAluthgeBot</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElektrikAkar</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JuliaRegistrator</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ManonMarchand</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RussellGarwood</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VincentAuriau</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aloctavodia</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avehtari</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bioc-issue-bot</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bozaah</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chainer-ci</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cpondoc</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>doronbehar</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fingolfin</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>github-advanced-security[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hackmd-hub[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>harperjf</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jClugstor</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jmineau</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kanav99</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ldouteau</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lumberbot-app[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>martenson</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mergify[bot]</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mikelkou</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>natalie-wa</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>oscarbenjamin</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>plover0226</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rtimms</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>scverse-bot</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>slager</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spyder-bot</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sympy-bot</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>timholy</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transifex-integration[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>weblate</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>welcome[bot]</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>wlandau</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      contributor bimbas_type  confidence\n",
       "0                    Anurag-Varma       Human       0.862\n",
       "1                 DilumAluthgeBot         Bot       0.894\n",
       "2                    ElektrikAkar       Human       0.781\n",
       "3                JuliaRegistrator         Bot       0.886\n",
       "4                   ManonMarchand       Human       0.903\n",
       "5                  RussellGarwood         Bot       0.890\n",
       "6                   VincentAuriau         Bot       0.731\n",
       "7                     aloctavodia       Human       0.630\n",
       "8                        avehtari       Human       0.776\n",
       "9                  bioc-issue-bot         Bot       0.548\n",
       "10                         bozaah       Human       0.914\n",
       "11                     chainer-ci         Bot       0.723\n",
       "12                        cpondoc         Bot       0.840\n",
       "13                     doronbehar       Human       0.916\n",
       "14                      fingolfin       Human       0.803\n",
       "15            github-actions[bot]         Bot       0.145\n",
       "16  github-advanced-security[bot]         Bot       0.703\n",
       "17                hackmd-hub[bot]         Bot       0.751\n",
       "18                       harperjf         Bot       0.857\n",
       "19                      jClugstor       Human       0.809\n",
       "20                        jmineau       Human       0.802\n",
       "21                        kanav99         Bot       0.800\n",
       "22                       ldouteau       Human       0.776\n",
       "23             lumberbot-app[bot]         Bot       0.912\n",
       "24                      martenson       Human       0.834\n",
       "25                   mergify[bot]       Human       0.786\n",
       "26                       mikelkou       Human       0.855\n",
       "27                     natalie-wa       Human       0.715\n",
       "28                  oscarbenjamin       Human       0.714\n",
       "29                     plover0226         Bot       0.752\n",
       "30                         rtimms       Human       0.851\n",
       "31                    scverse-bot         Bot       0.262\n",
       "32                         slager       Human       0.817\n",
       "33                     spyder-bot         Bot       0.692\n",
       "34                      sympy-bot         Bot       0.911\n",
       "35                        timholy       Human       0.900\n",
       "36     transifex-integration[bot]         Bot       0.535\n",
       "37                        weblate         Bot       0.866\n",
       "38                   welcome[bot]         Bot       0.727\n",
       "39                        wlandau       Human       0.897"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here to call execute_bimbas function. \n",
    "# Pass the contributors list and the filtered events DataFrame as argument to \"execute_bimbas\" function\n",
    "# Prediction returned by BIMBAS will have \"contributor\", \"bimbas_type\" and \"confidence\"\n",
    "# Note: Print the prediction provided by BIMBAS - else this cell will not be graded.\n",
    "\n",
    "# YOUR CODE BELOW\n",
    "\n",
    "bimbas_predict = execute_bimbas(contributors_list, filtered_events)\n",
    "\n",
    "bimbas_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840554c-ed7e-4bc0-a37a-842c6117441b",
   "metadata": {},
   "source": [
    "### Create a column in your predictions DataFrame to have predictions provided by BIMBAS. \n",
    "### Now your DataFrame should have the following columns - contributor, bothunter_type, app, bimbas_type, confidence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8a42e-0c0f-499e-bc96-92c13b3debf0",
   "metadata": {},
   "source": [
    "### Merging bothunter and bimbas predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f4dd46-d8a8-492b-91d1-5f68d0e88a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the predictions provided by BIMBAS to the resultant dataset of Section 3. This final DataFrame should have the following columns - \n",
    "# contributor, bothunter_type, user_type, bimbas_type, and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad85279-0ee8-49de-8c5a-bf0850494772",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "#### Using Cohen's Kappa compute and report the interrater agreement score between the labels computed by both the bot identification approaches. Mention your interpretation of Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1040a69f-25cb-467a-9afd-6f32f6ae2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: use the cohen_kappa_score library\n",
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f38f75-30ec-463f-bc98-89de44a14db4",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "#### Determine the final type of each contributor. Whenever user_type column has the value \"User\" check if both bimbas_type and bothunter_type give the same prediction, then consider it as your final prediction in \"acc_type\" column.\n",
    "#### For the contributors that have different predictions, i.e. bimbas_type is not same as bothunter_type, then make a manual verification and consider that as the type for that contributor. Add an extra column to the DataFrame ﬁle called 'manual' that has the label determined by you. \n",
    "#### For manual verification you can make use the GitHub UI and the GitHub API https://api.github.com/users/username\n",
    "\n",
    "#### Whenever user_type column has the value \"Bot\", directly write your final acc_type as \"Bot Actor\"\n",
    "\n",
    "#### More information:\n",
    "For each contributor, you can look at their activities in GitHub UI, look at their latest events using GitHub Events API - https://api.github.com/users/<contributor>/events, to make a decision on their type.\n",
    "\n",
    "In addition, you can also write a very small reason why do you think they are bot or human (e.g., same activity at regular interval so Bot, files committed and code modified looks like Human, comments look like Human, comment look like Bot, test report looks automated so Bot, and so on....). This will be useful to answer your next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884a7612-7ff7-40a4-805f-113c6f70786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your manual decision here\n",
    "# example : \n",
    "# manual_list_dict = [{'contributor': '<contributor name>', 'manual': '<your prediction>'}, {....}, {....}, {....}]\n",
    "# pd.DataFrame.from_dict(manual_list_dict)\n",
    "\n",
    "# YOUR CODE BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c4ce14-c393-45ba-aba0-bf1ae23d1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below here to determine the final type of contributor.\n",
    "# add column named 'acc_type' and write your final decision in it. Final decision is majority of three types - bimbas_type, bothunter_type, manual.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42ed1-0758-4ce4-82cc-542e490626dc",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "#### Study and report the purpose of these identified bots and humans in the repository assigned to you.\n",
    "#### For example, the purpose can be based on but not limited to - \n",
    "##### 1) the type of activities that they are performing (releasing a version on every Sunday, updating the documentation), \n",
    "##### 2) type of comments they are posting (reviewing code, test summary report), \n",
    "##### 3) when are they triggered (when a new PR is created, when someone in the project ask the bot to merge the code) and so on.  \n",
    "#### Note: \n",
    "##### The purpose can be other than what is provided in examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64569eb1-7faa-46e4-bb81-02bb1058b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88945f23-8222-4925-b6fc-b049b0761a7a",
   "metadata": {},
   "source": [
    "## Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d107b13-0c4f-4a56-a284-596f73a53d2f",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### Use the filtered events file that has the events performed by the contributors provided to you\n",
    "#### Group each event into the following four categories\n",
    "\n",
    "Issues: IssueCommentEvent, IssuesEvent  \n",
    "Pull Requests: PullRequestEvent, PullRequestReviewCommentEvent  \n",
    "Commits: CommitCommentEvent, PushEvent  \n",
    "Repository: CreateEvent, DeleteEvent, ForkEvent, GollumEvent, MemberEvent, PublicEvent, ReleaseEvent, SponsorshipEvent, WatchEvent  \n",
    "\n",
    "#### Hint:\n",
    "1. Add a column called event_group that mentions which event group does that event belong to. Each event (row) should correspond to an event group.  \n",
    "2. Then perform groupby on ['login','event_group'],  \n",
    "3. use .agg (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) to count the number of events performed by each contributor in each group,  \n",
    "4. use pivot with the required arguments (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html). An example is given [here](#pivot_example) in question 2(b), and\n",
    "5. Reset index and rename axis with None\n",
    "7. Finally merge it with your 'acc_type' field from the DataFrame you created in Section4, drop contributor, and fillna with 0\n",
    "8. The final DataFrame should have the following columns - login, PR, commit, issue, repo, acc_type\n",
    "\n",
    "The final DataFrame should be looking like the following  \n",
    "![](event_group.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06072cfd-9de7-4e25-a3fa-11296a728484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the resultant DataFrame - each row should corespond to a contributor, and the columns should have all the event groups  \n",
    "# and the type of the contributor (that you decided in the previous DataFrame) and the values should be the number \n",
    "# of events of that event event group the contriubutor has performed.\n",
    "\n",
    "issue_group = ['IssueCommentEvent', 'IssuesEvent']\n",
    "pr_group = ['PullRequestEvent', 'PullRequestReviewCommentEvent']\n",
    "commit_group = ['CommitCommentEvent', 'PushEvent']\n",
    "repo_group = ['CreateEvent', 'DeleteEvent', 'ForkEvent', 'GollumEvent', 'MemberEvent', 'PublicEvent', 'ReleaseEvent', 'SponsorshipEvent', 'WatchEvent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "326eaddf-c6f2-4e7e-a3e1-37183a3c90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8b35af-92af-4ffd-8d99-2dd34d865ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca3310-5bef-48f5-be38-e0861d5c43b6",
   "metadata": {},
   "source": [
    "### Question 2 (a)\n",
    "\n",
    "#### Compute the median number of events per event group for Bot+Bot actors and Humans and write in DataFrame.\n",
    "\n",
    "Row should correspond to type (Bot_BotActor and Human), Column should have Event group name and the values should be the median value of Bot_BotActor or Human for that particular event group. An example is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef89644a-1f38-4e67-81ab-c54db8d6c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_group</th>\n",
       "      <th>median</th>\n",
       "      <th>acc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event_group1</td>\n",
       "      <td>val1</td>\n",
       "      <td>Bot_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_group1</td>\n",
       "      <td>val2</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_group2</td>\n",
       "      <td>val3</td>\n",
       "      <td>Bot_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>event_group2</td>\n",
       "      <td>val4</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>event_group3</td>\n",
       "      <td>val5</td>\n",
       "      <td>Bot_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>event_group3</td>\n",
       "      <td>val6</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>event_group4</td>\n",
       "      <td>val7</td>\n",
       "      <td>Bot_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>event_group5</td>\n",
       "      <td>val8</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_group median acc_type\n",
       "0  event_group1   val1  Bot_app\n",
       "1  event_group1   val2    Human\n",
       "2  event_group2   val3  Bot_app\n",
       "3  event_group2   val4    Human\n",
       "4  event_group3   val5  Bot_app\n",
       "5  event_group3   val6    Human\n",
       "6  event_group4   val7  Bot_app\n",
       "7  event_group5   val8    Human"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example:\n",
    "medians = [{'event_group': 'event_group1', 'median': 'val1', 'acc_type': 'Bot_app'}, \n",
    "           {'event_group': 'event_group1', 'median': 'val2', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group2', 'median': 'val3', 'acc_type': 'Bot_app'},\n",
    "           {'event_group': 'event_group2', 'median': 'val4', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group3', 'median': 'val5', 'acc_type': 'Bot_app'},\n",
    "           {'event_group': 'event_group3', 'median': 'val6', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group4', 'median': 'val7', 'acc_type': 'Bot_app'},\n",
    "           {'event_group': 'event_group5', 'median': 'val8', 'acc_type': 'Human'}]\n",
    "df_medians = pd.DataFrame.from_dict(medians)\n",
    "df_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c3dc1ce-f19c-44b7-8fa1-35df0ffaa936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafa8a6-3c98-41db-bebd-64adc634f77f",
   "metadata": {},
   "source": [
    "### Question 2 (b)\n",
    "\n",
    "Plot a heatmap of the DataFrame using seaborn - \n",
    "1. First convert the dataframe to the required format using pivot, example is given below\n",
    "2. plot using seaborn - sns.heatmap(df_medians, annot=True, vmin=0, vmax=300, cmap=\"crest\"). More details: https://seaborn.pydata.org/generated/seaborn.heatmap.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd13bb8-628d-444e-b4a2-9887378a9cef",
   "metadata": {},
   "source": [
    "#### pd.pivot example:\n",
    "<a id='pivot_example'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fbf8d1e-86ba-4b86-8bfc-d1bba83c63a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_group</th>\n",
       "      <th>median</th>\n",
       "      <th>acc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event_group1</td>\n",
       "      <td>val1</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_group1</td>\n",
       "      <td>val2</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_group2</td>\n",
       "      <td>val3</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>event_group2</td>\n",
       "      <td>val4</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>event_group3</td>\n",
       "      <td>val5</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>event_group3</td>\n",
       "      <td>val6</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>event_group4</td>\n",
       "      <td>val7</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>event_group5</td>\n",
       "      <td>val8</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_group median acc_type\n",
       "0  event_group1   val1      Bot\n",
       "1  event_group1   val2    Human\n",
       "2  event_group2   val3      Bot\n",
       "3  event_group2   val4    Human\n",
       "4  event_group3   val5      Bot\n",
       "5  event_group3   val6    Human\n",
       "6  event_group4   val7      Bot\n",
       "7  event_group5   val8    Human"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main DataFrame\n",
    "medians = [{'event_group': 'event_group1', 'median': 'val1', 'acc_type': 'Bot'}, \n",
    "           {'event_group': 'event_group1', 'median': 'val2', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group2', 'median': 'val3', 'acc_type': 'Bot'},\n",
    "           {'event_group': 'event_group2', 'median': 'val4', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group3', 'median': 'val5', 'acc_type': 'Bot'},\n",
    "           {'event_group': 'event_group3', 'median': 'val6', 'acc_type': 'Human'},\n",
    "           {'event_group': 'event_group4', 'median': 'val7', 'acc_type': 'Bot'},\n",
    "           {'event_group': 'event_group5', 'median': 'val8', 'acc_type': 'Human'}]\n",
    "df_medians = pd.DataFrame.from_dict(medians)\n",
    "df_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "816f28a7-c281-4808-b987-5d74a1c08271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>event_group</th>\n",
       "      <th>event_group1</th>\n",
       "      <th>event_group2</th>\n",
       "      <th>event_group3</th>\n",
       "      <th>event_group4</th>\n",
       "      <th>event_group5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>val1</td>\n",
       "      <td>val3</td>\n",
       "      <td>val5</td>\n",
       "      <td>val7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>val2</td>\n",
       "      <td>val4</td>\n",
       "      <td>val6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>val8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "event_group event_group1 event_group2 event_group3 event_group4 event_group5\n",
       "acc_type                                                                    \n",
       "Bot                 val1         val3         val5         val7          NaN\n",
       "Human               val2         val4         val6          NaN         val8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot the main DataFrame\n",
    "df_medians.pivot(index='acc_type', columns='event_group', values='median')#.reset_index().rename_axis(None,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24478c26-f367-4589-85dc-3cfa22614f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab7b9ff6-1286-4c5b-a604-5459b6d2b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d518fd-10f0-4f91-a38e-595fe89f36a2",
   "metadata": {},
   "source": [
    "#### What is the difference that you observe between Bots+Bot actors and Humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a1600-7110-4866-9de3-42b85b407722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bbc377f-79bb-4b52-9bba-fe7cc4a804ab",
   "metadata": {},
   "source": [
    "#### What is the differnce that you observe between Event groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cc1a2-c910-47a8-b327-deba02a815a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e941d75-0450-46f4-9345-d7f109ff9b92",
   "metadata": {},
   "source": [
    "#### What is the difference that you observe between Bots+Bot actors and Humans and Event groups all considering at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145cbf9-e9a6-4798-aa23-54428bc7f73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c402f2c-2628-4957-ac76-e48bb85564cf",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd623c-4bc5-4cef-9649-fb8cdd41e981",
   "metadata": {},
   "source": [
    "#### Create boxen plots to visualise the distribution of number of events in each event group. \n",
    "#### For more information you can visit - https://seaborn.pydata.org/generated/seaborn.boxenplot.html#seaborn.boxenplot \n",
    "#### You should highlight the data points that correspond to bots using a stripplot in seaborn. https://seaborn.pydata.org/tutorial/categorical.html#categorical-tutorial  \n",
    "#### Interpret the results of the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a499ac-e0c7-4b0d-9f90-78b704a13ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW - Visualize number of events from pull request event group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "330c9d73-28a9-4d83-9728-cf595374235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW - Visualise number of events from issue event group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7ec1644-8c4d-4bd8-b504-3196ddab982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW - Visualise number of events from commit event group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c2536a-0f6c-4f2e-a8a5-b07e8abf5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW - Visualise number of events from repo event group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663a24f-ebbd-4707-a8e2-c4a72a9451a7",
   "metadata": {},
   "source": [
    "### Question 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2541bc-5f3a-4ce3-bfb1-21e16104b4c5",
   "metadata": {},
   "source": [
    "#### Statistical identify whether number of events in each event group is normally distributed or not.\n",
    "#### Null hypothesis - $H_0$: Sample comes from the data that has normal distribution.\n",
    "#### Use Shapiro-Wilk test for this purpose. Use the p-value with a threshold of 0.05 to determine whether $H_0$ can be rejected with statistical significance or not. \n",
    "\n",
    "#### Use shapiro from scipy.stats to perform this test (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4273e9c-f29f-4b46-ab75-3ceb16a2aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8617f-a3ed-40ad-8b2f-7ff0a41c3518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ed78ce-6901-4ddb-a219-d5a8c4e26886",
   "metadata": {},
   "source": [
    "### Question 4.2\n",
    "#### Determine if there is any statistical diﬀerence in number of events between the identified event groups. Perform this test on all pairs of event groups. \n",
    "#### Null hypothesis - $H_0$: Any two event group come from the same population.\n",
    "#### If $H_0$ is rejected in Shapiro-Wilk test (at least for one of the two event groups considered for test), use the Mann-Whitney U statistical test for this purpose. If $H_0$ is not rejected in Shapiro-Wilk test, use the independent t-test for this purpose.  \n",
    "#### In any case, use the p-value with a threshold of 0.01 to determine whether $H_0$ can be rejected with statistical significance. \n",
    "\n",
    "#### Use mannwhitneyu from scipy.stats to perform Mann-Whitney U test (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html) \n",
    "#### or \n",
    "#### ttest_ind from scipy.stats to perform independent t-test https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fe255-f6a8-4c49-92aa-1859c98d51c1",
   "metadata": {},
   "source": [
    "#### More information:\n",
    "\n",
    "You can pass the following arguments to mannwhitneyu from scipy.stats - (method='exact', nan_policy='omit'). For ttest_ind you can use - (nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e7c952f-15a8-4634-b786-90ff1e8f20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443dbbc-a8f1-4281-aadb-8ec8f9c792da",
   "metadata": {},
   "source": [
    "### Question 4.3\n",
    "#### Each time you reject the null hypothesis $H_0$, quantify the effect size of the diﬀerence between the groups using cliﬀ’s delta ($\\delta$). \n",
    "#### To calculate cliﬀ’s delta, you can pass the list of values to cliﬀ delta.py file given in the repository. E.g., cliffsDelta.cliffsDelta(list of values, list of values). This will return the effect size.\n",
    "#### Refer to the table given in the TP document and mention your interpretation (negligible, small, medium, large)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a6054-933f-425b-971e-d54a429c901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317fab1-5f0e-463f-b2d4-18a2754dee48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c5872-7d00-4265-9f1b-122d59771226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
